{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/smpstk6x2kd_pppyythh4r300000gn/T/ipykernel_56513/1088461914.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/Users/sujairibrahim/ML-Projects/LLMA/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/s0/smpstk6x2kd_pppyythh4r300000gn/T/ipykernel_56513/1088461914.py:16: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(persist_directory=chroma_db_path, embedding_function=embedding_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stored 528 chunks in ChromaDB!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/smpstk6x2kd_pppyythh4r300000gn/T/ipykernel_56513/1088461914.py:27: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_store.persist()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_db_path = \"./grownius_vdbI\"\n",
    "vector_store = Chroma(persist_directory=chroma_db_path, embedding_function=embedding_model)\n",
    "\n",
    "# Load text and split it into chunks\n",
    "def store_knowledge(file_path):\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    vector_store.add_documents(docs)\n",
    "    vector_store.persist()\n",
    "    print(f\"✅ Stored {len(docs)} chunks in ChromaDB!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    store_knowledge(\"crop_suggestions_grownius.txt\")  # Replace with your actual file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Information:\n",
      " *   Water the crop deeply but infrequently to encourage deep root growth\n",
      "    *   Monitor humidity levels, ideally between 60-80% for healthy growth\n",
      "    *   Protect the crop from extreme temperature fluctuations (above 35°C or below 15°C)\n",
      "================================================================================\n",
      "\n",
      "*   Water the crop deeply but infrequently to encourage deep root growth\n",
      "    *   Monitor humidity levels, ideally between 60-80% for healthy growth\n",
      "    *   Protect the crop from extreme temperature fluctuations (above 35°C or below 15°C)\n",
      "================================================================================\n",
      "\n",
      "Primary Crop: orange\n",
      "Input Conditions: {'N': '33', 'P': '14', 'K': '8', 'pH': '7.684420446', 'Rainfall': '110.6823944', 'Humidity': '92.9641969', 'Temperature': '21.03200078'}\n",
      "LLaMA Suggestions:\n",
      "**Farming Suggestions**\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load ChromaDB\n",
    "vector_store = Chroma(persist_directory=\"./grownius_vdb\", embedding_function=embedding_model)\n",
    "\n",
    "def retrieve_context(query, top_k=3):\n",
    "    \"\"\"Retrieves relevant information using similarity search.\"\"\"\n",
    "    results = vector_store.similarity_search(query, k=top_k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in results]) if results else \"No relevant information found.\"\n",
    "\n",
    "# Test retrieval\n",
    "sample_query = \"What crops grow well in dry climates?\"\n",
    "print(\"Retrieved Information:\\n\", retrieve_context(sample_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from fastapi import FastAPI, Query\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"❌ API key not found in .env file!\")\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = Chroma(persist_directory=\"./grownius_vdb\", embedding_function=embedding_model)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def retrieve_context(query, top_k=3):\n",
    "    \"\"\"Retrieves relevant knowledge from ChromaDB.\"\"\"\n",
    "    results = vector_store.similarity_search(query, k=top_k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in results]) if results else \"\"\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat_with_rag(\n",
    "    feature_1: str = Query(None),\n",
    "    feature_2: str = Query(None),\n",
    "    feature_3: str = Query(None),\n",
    "    feature_4: str = Query(None),\n",
    "    feature_5: str = Query(None),\n",
    "    feature_6: str = Query(None),\n",
    "    feature_7: str = Query(None),\n",
    "    crop_name: str = Query(None),\n",
    "    model_prediction: str = Query(None),\n",
    "    user_query: str = Query(...)\n",
    "):\n",
    "    \"\"\"Handles user queries using retrieved knowledge and OpenRouter's GPT-4o.\"\"\"\n",
    "    \n",
    "    user_input = f\"Crop: {crop_name}\" if crop_name else \"\\n\".join([feat for feat in [feature_1, feature_2, feature_3, feature_4, feature_5, feature_6, feature_7] if feat])\n",
    "    context = retrieve_context(user_query)\n",
    "\n",
    "    if not context:\n",
    "        return {\"response\": \"I'm sorry, but I couldn't find relevant information in the database.\"}\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant. Provide responses strictly based on retrieved knowledge.\n",
    "\n",
    "    ### User Input:  \n",
    "    {user_input}\n",
    "\n",
    "    ### Retrieved Knowledge:  \n",
    "    {context}\n",
    "\n",
    "    ### Query:  \n",
    "    {user_query}\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\"model\": \"openai/gpt-4o\", \"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "\n",
    "    return {\"response\": response.json()[\"choices\"][0][\"message\"][\"content\"]} if response.status_code == 200 else {\"error\": response.text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AI Response:\n",
      " ### Farming Suggestions for Maize\n",
      "\n",
      "#### Best Irrigation Method:\n",
      "For maize, the best irrigation methods are usually drip or sprinkler systems. These methods efficiently supply water directly to the plant roots, minimizing water wastage and ensuring the crops receive adequate moisture, especially with your conditions of 120mm rainfall and 70% humidity.\n",
      "\n",
      "#### Recommended Fertilizers:\n",
      "1. Nitrogen (N) fertilizers are important. Ideally, use urea or ammonium nitrate.\n",
      "2. Phosphorus (P) can be supplemented with diammonium phosphate (DAP) or triple superphosphate (TSP).\n",
      "3. Potassium (K) needs can be met using muriate of potash (MOP).\n",
      "\n",
      "Ensure to apply these fertilizers based on soil test results and local agricultural guidelines to match your conditions of N: 45, P: 30, K: 20, and pH: 6.5.\n",
      "\n",
      "#### Secondary Crop:\n",
      "Soybean or sunflower can be recommended as secondary crops with maize. They provide rotational benefits and help with pest control, improving soil health and reducing disease prevalence.\n",
      "\n",
      "#### Additional Care Tips:\n",
      "- Monitor and control pests such as corn borers and fall armyworms with appropriate biological or chemical measures.\n",
      "- Ensure proper weed management to reduce competition for nutrients and water.\n",
      "- Regularly monitor soil pH and adjust if necessary to maintain an optimal level for maize growth.\n",
      "- Consider employing integrated pest management (IPM) strategies for sustainable pest control.\n",
      "- Ensure crop residues are managed post-harvest to maintain soil fertility and health.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"❌ API key not found in .env file!\")\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load ChromaDB\n",
    "vector_store = Chroma(persist_directory=\"./grownius_vdb\", embedding_function=embedding_model)\n",
    "\n",
    "# Retrieve context from ChromaDB\n",
    "def retrieve_context(query, top_k=3):\n",
    "    results = vector_store.similarity_search(query, k=top_k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in results]) if results else \"No relevant information found.\"\n",
    "\n",
    "# Test chatbot retrieval\n",
    "def test_chatbot():\n",
    "    sample_query = \"N: 45, P: 30, K: 20, pH: 6.5, temperature: 28°C, rainfall: 120mm, humidity: 70%.. and the recommended crop is maize. so give me the best irrigation, fertilizers, seconday crop, additional care tips.\"\n",
    "    \n",
    "    # Retrieve knowledge\n",
    "    context = retrieve_context(sample_query)\n",
    "\n",
    "    if not context:\n",
    "        print(\"❌ No relevant information found in the database.\")\n",
    "        return\n",
    "\n",
    "    # Create chatbot prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant. Provide responses strictly based on retrieved knowledge.\n",
    "\n",
    "    ### Retrieved Knowledge:  \n",
    "    {context}\n",
    "\n",
    "    ### Query:  \n",
    "    {sample_query}\n",
    "    \"\"\"\n",
    "\n",
    "    # API request\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\"model\": \"openai/gpt-4o\", \"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # Print response\n",
    "    if response.status_code == 200:\n",
    "        print(\"✅ AI Response:\\n\", response.json()[\"choices\"][0][\"message\"][\"content\"])\n",
    "    else:\n",
    "        print(\"❌ API Error:\", response.text)\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    test_chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
